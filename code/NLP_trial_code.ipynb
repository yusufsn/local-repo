{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference](https://towardsdatascience.com/an-easy-introduction-to-natural-language-processing-b1e2801291c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we’ll install a few useful Python NLP libraries that will aid us in analysing this text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing spaCy, general Python NLP lib\n",
    "`pip3 install spacy`\n",
    "### Downloading the English dictionary model for spaCy\n",
    "`python3 -m spacy download en_core_web_lg`\n",
    "### Installing textacy, basically a useful add-on to spaCy\n",
    "`pip3 install textacy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is installed, we can do a quick entity analysis of our text. Entity analysis will go through your text and identify all of the important words or “entities” in the text. When we say “important” what we really mean is words that have some kind of real-world semantic meaning or significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### coding: utf-8\n",
    "import spacy\n",
    "\n",
    "### Load spaCy's English NLP model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "### The text we want to examine\n",
    "text = \"Amazon.com, Inc., doing business as Amazon, is an American electronic commerce and cloud computing company based in Seattle, Washington, that was founded by Jeff Bezos on July 5, 1994. The tech giant is the largest Internet retailer in the world as measured by revenue and market capitalization, and second largest after Alibaba Group in terms of total sales. The amazon.com website started as an online bookstore and later diversified to sell video downloads/streaming, MP3 downloads/streaming, audiobook downloads/streaming, software, video games, electronics, apparel, furniture, food, toys, and jewelry. The company also produces consumer electronics - Kindle e-readers, Fire tablets, Fire TV, and Echo - and is the world's largest provider of cloud infrastructure services (IaaS and PaaS). Amazon also sells certain low-end products under its in-house brand AmazonBasics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse the text with spaCy\n",
    "### Our 'document' variable now contains a parsed version of text.\n",
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load spaCy’s learned ML model and initialise the text want to process. We run the ML model on our text to extract the entities. When you run that code you’ll get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon.com, Inc. ORG\n",
      "Amazon ORG\n",
      "American NORP\n",
      "Seattle GPE\n",
      "Washington GPE\n",
      "Jeff Bezos PERSON\n",
      "July 5, 1994 DATE\n",
      "second ORDINAL\n",
      "Alibaba Group ORG\n",
      "amazon.com ORG\n",
      "Fire TV ORG\n",
      "Echo -  LOC\n",
      "PaaS ORG\n",
      "Amazon ORG\n",
      "AmazonBasics ORG\n"
     ]
    }
   ],
   "source": [
    "### print out all the named entities that were detected\n",
    "for entity in document.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [3 letter codes](https://spacy.io/usage/linguistic-features#entity-types) beside the text are labels which indicate the type of entity we are looking at. Looks like our model did a pretty good job! Jeff Bezos is indeed a person, the date is identified correctly, Amazon is an organisation, and both Seattle and Washington are Geopolitical entities (i.e countries, cities, states, etc). The only tricky ones it got wrong were that things like Fire TV and Echo are actually products, not organisations. It also missed out on the other things that Amazon sells “*video downloads/streaming, MP3 downloads/streaming, audiobook downloads/streaming, software, video games, electronics, apparel, furniture, food, toys, and jewelry,*” probably because they were in a big, uncapitalised list and thus looked fairly unimportant.\n",
    "\n",
    "Overall our model has accomplished what we wanted to. Imagine we had a huge document full of hundreds of pages of text. This NLP model could quickly get you an overview of what the document is about and what the key entities in it are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operating on entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try and do something a bit more applicable. Let’s say you have the same block of text as above, but you would like to remove the names of all people and organisations automatically, for privacy concerns. The spaCy library has a very useful `scrub` function which we can use to scrub away any entity categories we don’t want to see. Here’s what that would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace a specific entity with the word \"PRIVATE\"\n",
    "def replace_entity_with_placeholder(token):\n",
    "    if token.ent_iob != 0 and (token.ent_type_ == \"PERSON\" or token.ent_type_ == \"ORG\"):\n",
    "        return \"[PRIVATE] \"\n",
    "    else:\n",
    "        return token.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loop through all the entities in a piece of text and apply entity replacement\n",
    "def scrub(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        ent.merge()\n",
    "    tokens = map(replace_entity_with_placeholder, doc)\n",
    "    return \"\".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRIVATE] , doing business as [PRIVATE] , is an American electronic commerce and cloud computing company based in Seattle, Washington, that was founded by [PRIVATE] on July 5, 1994. The tech giant is the largest Internet retailer in the world as measured by revenue and market capitalization, and second largest after [PRIVATE] in terms of total sales. The [PRIVATE] website started as an online bookstore and later diversified to sell video downloads/streaming, MP3 downloads/streaming, audiobook downloads/streaming, software, video games, electronics, apparel, furniture, food, toys, and jewelry. The company also produces consumer electronics - Kindle e-readers, Fire tablets, [PRIVATE] , and Echo - and is the world's largest provider of cloud infrastructure services (IaaS and [PRIVATE] ). [PRIVATE] also sells certain low-end products under its in-house brand [PRIVATE] .\n"
     ]
    }
   ],
   "source": [
    "print(scrub(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked great! This is actually an incredibly powerful technique. People use the `ctrl + f` function on their computer all the time to find and replace words in their document. But with NLP, we can find and replace *specific entities*, taking into account their semantic meaning and not just their raw text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting information from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library the we installed previously `textacy` implements several common NLP information extraction algorithms on top of spaCy. It’ll let us do a few more advanced things than the simple out of the box stuff.\n",
    "\n",
    "One of the algorithms it implements is called [Semi-structured Statement Extraction](https://www.pydoc.io/pypi/textacy-0.5.0/autoapi/extract/index.html#extract.semistructured_statements). This algorithm essentially parses some of the information that spaCy’s NLP model was able to extract and based on that we can grab some more specific information about certain entities! In a nutshell, we can extract certain “facts” about the entity of our choice.\n",
    "\n",
    "Let’s see what that looks like in code. For this one, we’re going to take the *entire summary* of Washington D.C’s Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import spacy\n",
    "import textacy.extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The text we want to examine\n",
    "text = \"\"\"Washington, D.C., formally the District of Columbia and commonly referred to as Washington or D.C., is the capital of the United States of America.[4] Founded after the American Revolution as the seat of government of the newly independent country, Washington was named after George Washington, first President of the United States and Founding Father.[5] Washington is the principal city of the Washington metropolitan area, which has a population of 6,131,977.[6] As the seat of the United States federal government and several international organizations, the city is an important world political capital.[7] Washington is one of the most visited cities in the world, with more than 20 million annual tourists.[8][9]\n",
    "The signing of the Residence Act on July 16, 1790, approved the creation of a capital district located along the Potomac River on the country's East Coast. The U.S. Constitution provided for a federal district under the exclusive jurisdiction of the Congress and the District is therefore not a part of any state. The states of Maryland and Virginia each donated land to form the federal district, which included the pre-existing settlements of Georgetown and Alexandria. Named in honor of President George Washington, the City of Washington was founded in 1791 to serve as the new national capital. In 1846, Congress returned the land originally ceded by Virginia; in 1871, it created a single municipal government for the remaining portion of the District.\n",
    "Washington had an estimated population of 693,972 as of July 2017, making it the 20th largest American city by population. Commuters from the surrounding Maryland and Virginia suburbs raise the city's daytime population to more than one million during the workweek. The Washington metropolitan area, of which the District is the principal city, has a population of over 6 million, the sixth-largest metropolitan statistical area in the country.\n",
    "All three branches of the U.S. federal government are centered in the District: U.S. Congress (legislative), President (executive), and the U.S. Supreme Court (judicial). Washington is home to many national monuments and museums, which are primarily situated on or around the National Mall. The city hosts 177 foreign embassies as well as the headquarters of many international organizations, trade unions, non-profit, lobbying groups, and professional associations, including the Organization of American States, AARP, the National Geographic Society, the Human Rights Campaign, the International Finance Corporation, and the American Red Cross.\n",
    "A locally elected mayor and a 13‑member council have governed the District since 1973. However, Congress maintains supreme authority over the city and may overturn local laws. D.C. residents elect a non-voting, at-large congressional delegate to the House of Representatives, but the District has no representation in the Senate. The District receives three electoral votes in presidential elections as permitted by the Twenty-third Amendment to the United States Constitution, ratified in 1961.\"\"\"\n",
    "### Parse the text with spaCy\n",
    "### Our 'document' variable now contains a parsed version of text.\n",
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Information from Washington's Wikipedia page ****\n",
      "1 - Statement:  (Washington, is, the capital of the United States of America.[4)\n",
      "1 - Fact:  the capital of the United States of America.[4\n",
      "2 - Statement:  (Washington, is, the principal city of the Washington metropolitan area, which has a population of 6,131,977.[6)\n",
      "2 - Fact:  the principal city of the Washington metropolitan area, which has a population of 6,131,977.[6\n",
      "3 - Statement:  (Washington, is, home to many national monuments and museums, which are primarily situated on or around the National Mall)\n",
      "3 - Fact:  home to many national monuments and museums, which are primarily situated on or around the National Mall\n"
     ]
    }
   ],
   "source": [
    "### Extracting semi-structured statements\n",
    "statements = textacy.extract.semistructured_statements(document, \"Washington\")\n",
    "\n",
    "print(\"**** Information from Washington's Wikipedia page ****\")\n",
    "count = 1\n",
    "for statement in statements:\n",
    "    subject, verb, fact = statement\n",
    "    print(str(count) + \" - Statement: \", statement)\n",
    "    print(str(count) + \" - Fact: \", fact)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our NLP model found 3 useful facts about Washington D.C from that text:\n",
    "\n",
    "(1) Washington is the capital of the USA\n",
    "\n",
    "(2) Washington’s population and the fact that it is metropolitan\n",
    "\n",
    "(3) Many national monuments and museums\n",
    "\n",
    "The best part about this is that those are all really the most important pieces of information within that block of text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
