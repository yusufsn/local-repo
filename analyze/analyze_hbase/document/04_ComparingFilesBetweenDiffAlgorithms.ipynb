{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, json, csv, subprocess, sys, re, operator\n",
    "from git import *\n",
    "from subprocess import Popen, PIPE\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as ply\n",
    "import plotly\n",
    "from plotly.offline import plot, init_notebook_mode, iplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userhome = os.path.expanduser('~')\n",
    "repository = os.path.dirname(userhome + r'/different-diff/dataset/hbase/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up the analyze directory\n",
    "analyze_dir = userhome + r'/different-diff/analyze/analyze_hbase/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining function to execute git command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_command(cmd, work_dir):\n",
    "    \"\"\"Executes a shell command in a subprocess, waiting until it has completed.\n",
    " \n",
    "    :param cmd: Command to execute.\n",
    "    :param work_dir: Working directory path.\n",
    "    \"\"\"\n",
    "    pipe = subprocess.Popen(cmd, shell=True, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    (out, error) = pipe.communicate()\n",
    "    return out, error\n",
    "    pipe.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms = ['histogram','minimal','myers','patience']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing files with bugs introducing based on the number of line changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding files and their paths with different number of line changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames = ['bug_id','bugintro_commitID','parent_id','filename','#deletions-hist','#deletions-myers','#deletions-min','#deletions-pat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the csv file with number of line changed between diff-algorithms\n",
    "data = pd.read_csv(analyze_dir + 'file-diff/diffbugs_file.csv')\n",
    "data = data[colnames]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[154][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfhist = pd.read_csv(analyze_dir + 'file-diff/diffhist-bugs.csv')\n",
    "dfmin = pd.read_csv(analyze_dir + 'file-diff/diffmin-bugs.csv')\n",
    "dfmyers = pd.read_csv(analyze_dir + 'file-diff/diffmyers-bugs.csv')\n",
    "dfpat = pd.read_csv(analyze_dir + 'file-diff/diffpat-bugs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['bug_id','bugintro_commitID','parent_id','#insertions','#deletions','filename','#line_changed']\n",
    "dthist = dfhist[cols][dfhist[cols]['#deletions'] != 0]\n",
    "dtmin = dfmin[cols][dfmin[cols]['#deletions'] != 0]\n",
    "dtmyers = dfmyers[cols][dfmyers[cols]['#deletions'] != 0]\n",
    "dtpat = dfpat[cols][dfpat[cols]['#deletions'] != 0]\n",
    "dthist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dthist.iloc[568][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_algorithm = [dthist, dtmin, dtmyers, dtpat]\n",
    "for da, dt_alg in enumerate(data_algorithm):\n",
    "    filename = []\n",
    "    for jj in range(0,len(dt_alg)):\n",
    "        if dt_alg.iloc[jj]['#deletions'] != 0:\n",
    "            filename.append(((dt_alg.iloc[jj][5].split('/'))[-1:])[0] + \"_\"+ dt_alg.iloc[jj][1] + \"-\" + dt_alg.iloc[jj][2][:10] + \"_\" + dt_alg.iloc[jj][0])\n",
    "\n",
    "    with open(analyze_dir + 'file-diff/filename/filename_'+ algorithms[da] + '.txt', mode='wt', encoding=\"utf-8\") as myfile:\n",
    "        myfile.write('\\n'.join(filename))\n",
    "\n",
    "print (\"Filename_<algorithm-name>.txt has been created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['bug_id','bugintro_commitID','parent_id']\n",
    "dtparent = pd.read_csv(analyze_dir + \"file-diff/parentid.csv\")\n",
    "dtparent = dtparent[cols]\n",
    "dtparent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the changes in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dthist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_hist = (open(analyze_dir + 'file-diff/filename/filename_histogram.txt')).read().split('\\n')\n",
    "fn_min = (open(analyze_dir + 'file-diff/filename/filename_minimal.txt')).read().split('\\n')\n",
    "fn_myers = (open(analyze_dir + 'file-diff/filename/filename_myers.txt')).read().split('\\n')\n",
    "fn_pat = (open(analyze_dir + 'file-diff/filename/filename_patience.txt')).read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_names = [fn_hist, fn_min, fn_myers, fn_pat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dthist.iloc[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for n, d_algo in enumerate(data_algorithm):\n",
    "    f = []\n",
    "    for aa in range(0,len(d_algo)):\n",
    "        sys.stdout.write('\\r%i: ' %(n+1) + ' Extracting data %i' %(aa+1))\n",
    "        sys.stdout.flush()\n",
    "        name = analyze_dir + \"file-diff/diff-files/\" + f_names[n][aa] + \"_\" + algorithms[n] + \"changes.diff\"\n",
    "        diff_cmd = \"git diff -w --ignore-blank-lines --diff-algorithm=\" + algorithms[n] + \" \" + d_algo.iloc[aa][2] + \" \" + d_algo.iloc[aa][1] + \" -- \" + d_algo.iloc[aa][5] + \" > \" + name\n",
    "        execute_command(diff_cmd, repository)\n",
    "        if os.stat(name).st_size == 0:\n",
    "            try:\n",
    "                os.remove(name)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        else:\n",
    "            f.append(f_names[n][aa] + \"_\" + algorithms[n] + \"changes.diff\")\n",
    "    files.append(f)\n",
    "print('\\nExtraction is complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_compare = []\n",
    "for x in range(0,len(files[0])):\n",
    "    fc = []\n",
    "    for n,file in enumerate(files):\n",
    "        fc.append(file[x])\n",
    "    file_to_compare.append(fc)\n",
    "file_to_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for z in file_to_compare:\n",
    "    print (i,z)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to find different line in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clean_line(line):\n",
    "    return [entry.strip().lower() for entry in line if entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = analyze_dir + \"file-diff/\"\n",
    "path1 = path + \"diff-files/\"\n",
    "path2 = path + \"diff-line-of-files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = []\n",
    "for xx, ftc in enumerate(file_to_compare):\n",
    "    sys.stdout.write('\\rComparing file %i' %(xx+1))\n",
    "    sys.stdout.flush()\n",
    "    diff_of_diff = []\n",
    "    with open(path1 + ftc[0], 'r') as first_file, open(path1 + ftc[1], 'r') as second_file, open(path1 + ftc[2], 'r') as third_file, open(path1 + ftc[3], 'r') as fourth_file:\n",
    "        first_reader = csv.reader(first_file)\n",
    "        second_reader = csv.reader(second_file)\n",
    "        third_reader = csv.reader(third_file)\n",
    "        fourth_reader = csv.reader(fourth_file)\n",
    "\n",
    "        for first_line, second_line, third_line, fourth_line in zip(first_reader, second_reader, third_reader, fourth_reader):\n",
    "            first_list, second_list, third_list, fourth_list = get_clean_line(first_line), get_clean_line(second_line), get_clean_line(third_line), get_clean_line(fourth_line)\n",
    "\n",
    "            if (len(first_list) != len(second_list) or sorted(first_list) != sorted(second_list)) or (len(first_list) != len(third_list) or sorted(first_list) != sorted(third_list)) or (len(first_list) != len(fourth_list) or sorted(first_list) != sorted(fourth_list)) or (len(second_list) != len(third_list) or sorted(second_list) != sorted(third_list)) or (len(second_list) != len(fourth_list) or sorted(second_list) != sorted(fourth_list)) or (len(third_list) != len(fourth_list) or sorted(third_list) != sorted(fourth_list)):\n",
    "                temp = str('{} :=: {} :=: {} :=: {} :=: {}'.format(\n",
    "                    first_reader.line_num, first_list, second_list, third_list, fourth_list)).replace(\"['\",'').replace(\"']\",'').split(\":=:\")\n",
    "                diff_of_diff.append(temp)\n",
    "    \n",
    "    fname = re.search((\"[^~]*[-]\\d*\"), ftc[0])\n",
    "    fname = fname.group(0)\n",
    "    \n",
    "    with open (path2 + \"diff_of_diff_\" + fname + \".csv\", 'w') as csvfile:\n",
    "        cols = ['line_no','diffmyers-' + fname,'diffhistogram-' + fname,'diffminimal-' + fname,'diffpatience-' + fname]\n",
    "        writers = csv.writer(csvfile, delimiter=',')\n",
    "        writers.writerow(cols)\n",
    "        for line in diff_of_diff:\n",
    "            writers.writerow(line)\n",
    "    \n",
    "    fn.append(path2 + \"diff_of_diff_\" + fname + \".csv\")\n",
    "    \n",
    "print ('\\nComparing file is complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fn[124])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the buggy line of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buggylinefiles = []\n",
    "for n, d_algo in enumerate(data_algorithm):\n",
    "    bf = []\n",
    "    for aa in range(0,len(d_algo)):\n",
    "        sys.stdout.write('\\r%i: ' %(n+1) + ' Extracting data %i' %(aa+1))\n",
    "        sys.stdout.flush()\n",
    "        name = analyze_dir + \"file-diff/buggylines/\" + algorithms[n] + \"/\" + f_names[n][aa] + \"_\" + algorithms[n] + \"buglines_\" + str(aa+1) + \".diff\"\n",
    "        diff_cmd = \"git diff -U0 -w --ignore-blank-lines --diff-algorithm=\" + algorithms[n] + \" \" + d_algo.iloc[aa][2] + \" \" + d_algo.iloc[aa][1] + \" -- \" + d_algo.iloc[aa][5] + \" | grep '^[-]' | grep -Ev '^(--- a/|\\+\\+\\+ b/)' > \" + name\n",
    "        execute_command(diff_cmd, repository)\n",
    "        zzz = [d_algo.iloc[aa][0], d_algo.iloc[aa][1], d_algo.iloc[aa][2], d_algo.iloc[aa][5], (f_names[n][aa] + \"_\" + algorithms[n] + \"buglines_\" + str(aa+1) + \".diff\")]\n",
    "        bf.append(zzz)\n",
    "    bf = sorted(bf, key=operator.itemgetter(4,1,2,0))\n",
    "    buggylinefiles.append(bf)\n",
    "print('\\nExtraction is complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in enumerate(buggylinefiles):\n",
    "    print (b[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_file = []\n",
    "for m, algrt in enumerate(algorithms):\n",
    "    temp_file = []\n",
    "    s = 0\n",
    "    for f_name in glob.iglob(path + 'buggylines/' + algrt + '/*', recursive=True):\n",
    "        sys.stdout.write(\"\\r%i \" %(m+1) + \"Counting bugline for file %i\" %(s+1))\n",
    "        sys.stdout.flush()\n",
    "        s += 1\n",
    "        \n",
    "        temp_file.append(f_name)\n",
    "    temp_file.sort()\n",
    "    bug_file.append(temp_file)\n",
    "print (\"\\nReading files are complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.search(\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w+[_]|(?<=histogram\\/)(\\w+[_])(?<=[_])\",bug_file[0][321])\n",
    "pat = pat.group()[:-1]\n",
    "pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buggylinefiles[2][321]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting number of files and number of buggylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, algr in enumerate(algorithms):\n",
    "    total = []\n",
    "    for rr, f_name in enumerate(bug_file[n]):\n",
    "        sys.stdout.write(\"\\r%i \" %(n+1) + \"Counting bugline for file %i\" %(rr+1))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        fn = open(f_name, 'r')\n",
    "        fn = fn.read().split('\\n')\n",
    "        if \"--- /dev\" in fn[0]:\n",
    "            num = str(len(fn)-2)\n",
    "        else:\n",
    "            num = str(len(fn)-1)\n",
    "        \n",
    "        pattern = re.search(\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w+[_]|(?<=\" + algr + \"\\/)(\\w+[_])(?<=[_])\", f_name)\n",
    "        pattern = pattern.group()[:-1]\n",
    "        \n",
    "        current = [buggylinefiles[n][rr][0], buggylinefiles[n][rr][1], buggylinefiles[n][rr][2], buggylinefiles[n][rr][3], pattern, num]\n",
    "        total.append(current)\n",
    "    \n",
    "    total = sorted(total, key=operator.itemgetter(4,1,2,0))\n",
    "    \n",
    "    with open(path + \"number_of_files/\" + algr + \"_total_bugline.csv\", 'w') as myfile:\n",
    "        writers = csv.writer(myfile)\n",
    "        fields = ['bug_id','commit_id','parent_id','filepath','filename','number_of_buggyline']\n",
    "        writers.writerow(fields)\n",
    "        for row in total:\n",
    "            writers.writerow(row)\n",
    "            \n",
    "print (\"\\nCounting buggyline is finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_totalhist = pd.read_csv(analyze_dir + 'file-diff/number_of_files/histogram_total_bugline.csv')\n",
    "df_totalmin = pd.read_csv(analyze_dir + 'file-diff/number_of_files/minimal_total_bugline.csv')\n",
    "df_totalmyers = pd.read_csv(analyze_dir + 'file-diff/number_of_files/myers_total_bugline.csv')\n",
    "df_totalpat = pd.read_csv(analyze_dir + 'file-diff/number_of_files/patience_total_bugline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_frame = [df_totalhist, df_totalmin, df_totalmyers, df_totalpat]\n",
    "for d, dfr in enumerate(d_frame):\n",
    "    dframe = (pd.to_numeric(dfr['number_of_buggyline'], errors='coerce')\n",
    "           .groupby(dfr['filepath'])\n",
    "           .sum()\n",
    "           .to_frame()\n",
    "           .add_prefix('total')\n",
    "           .reset_index())\n",
    "\n",
    "    col = ['filepath','totalnumber_of_buggyline']\n",
    "    dframe = dframe.dropna(subset=['totalnumber_of_buggyline'])\n",
    "    dframe = dframe.sort_values('totalnumber_of_buggyline', ascending=False)\n",
    "\n",
    "    dframe[col].to_csv(analyze_dir + 'file-diff/number_of_files/totalbug_of_' + algorithms[d] + '_filechanged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfrhist = pd.read_csv(analyze_dir + 'file-diff/number_of_files/totalbug_of_histogram_filechanged.csv')\n",
    "dfrmin = pd.read_csv(analyze_dir + 'file-diff/number_of_files/totalbug_of_minimal_filechanged.csv')\n",
    "dfrmyers = pd.read_csv(analyze_dir + 'file-diff/number_of_files/totalbug_of_myers_filechanged.csv')\n",
    "dfrpat = pd.read_csv(analyze_dir + 'file-diff/number_of_files/totalbug_of_patience_filechanged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehist = dfrhist['filepath'][dfrhist['totalnumber_of_buggyline'] != 0].count()\n",
    "filemin = dfrmin['filepath'][dfrmin['totalnumber_of_buggyline'] != 0].count()\n",
    "filemyers = dfrmyers['filepath'][dfrmyers['totalnumber_of_buggyline'] != 0].count()\n",
    "filepat = dfrpat['filepath'][dfrpat['totalnumber_of_buggyline'] != 0].count()\n",
    "\n",
    "bglinehist = dfrhist['totalnumber_of_buggyline'].sum()\n",
    "bglinemin = dfrmin['totalnumber_of_buggyline'].sum()\n",
    "bglinemyers = dfrmyers['totalnumber_of_buggyline'].sum()\n",
    "bglinepat = dfrpat['totalnumber_of_buggyline'].sum()\n",
    "\n",
    "print (bglinehist,bglinemin,bglinemyers,bglinepat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Bar(\n",
    "    x = algorithms,\n",
    "    y = [filehist, filemin, filemyers, filepat],\n",
    "    text = [filehist, filemin, filemyers, filepat],\n",
    "    textposition = 'auto',\n",
    "    opacity = 0.6,\n",
    "    marker = dict(\n",
    "        color = 'rgb(150,255,200)',\n",
    "        line = dict(\n",
    "            color='rgb(8,48,107)',\n",
    "            width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "dtbar = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Number of files changed'\n",
    ")\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "fig = go.Figure(data=dtbar, layout=layout)\n",
    "iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = go.Bar(\n",
    "    x = algorithms,\n",
    "    y = [bglinehist, bglinemin, bglinemyers, bglinepat],\n",
    "    text = [bglinehist, bglinemin, bglinemyers, bglinepat],\n",
    "    textposition = 'auto',\n",
    "    opacity = 0.6,\n",
    "    marker = dict(\n",
    "        color = 'rgb(150,255,200)',\n",
    "        line = dict(\n",
    "            color='rgb(8,48,107)',\n",
    "            width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "dtbar = [graph]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Number of buglines'\n",
    ")\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "fig = go.Figure(data=dtbar, layout=layout)\n",
    "iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
