{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, json, csv, subprocess, sys, re\n",
    "from git import *\n",
    "from subprocess import Popen, PIPE\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as ply\n",
    "import plotly\n",
    "from plotly.offline import plot, init_notebook_mode, iplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userhome = os.path.expanduser('~')\n",
    "repository = userhome + r'/different-diff/dataset/hbase/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyze_dir = userhome + r'/different-diff/analyze/analyze_hbase/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening the earliest affected version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "affected_version = pd.read_csv(analyze_dir + 'step_3/affected_version/earliest_version.csv')\n",
    "cols = ['bug_id','earliest_affected_version','date_release']\n",
    "aff = affected_version[cols]\n",
    "aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining data histogram with earliest versions\n",
    "filedata_hist = pd.read_csv(analyze_dir + 'file-diff/number_of_files/histogram_total_bugline.csv')\n",
    "filedata_hist = filedata_hist[['bug_id', 'filepath', 'number_of_buggyline']]\n",
    "\n",
    "details_hist = filedata_hist.join(aff.set_index('bug_id')[['earliest_affected_version','date_release']], on='bug_id')\n",
    "#details_hist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining data minimal with earliest versions\n",
    "filedata_min = pd.read_csv(analyze_dir + 'file-diff/number_of_files/minimal_total_bugline.csv')\n",
    "filedata_min = filedata_min[['bug_id', 'filepath', 'number_of_buggyline']]\n",
    "\n",
    "details_min = filedata_min.join(aff.set_index('bug_id')[['earliest_affected_version','date_release']], on='bug_id')\n",
    "#details_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining data myers with earliest versions\n",
    "filedata_myers = pd.read_csv(analyze_dir + 'file-diff/number_of_files/myers_total_bugline.csv')\n",
    "filedata_myers = filedata_myers[['bug_id', 'filepath', 'number_of_buggyline']]\n",
    "\n",
    "details_myers = filedata_myers.join(aff.set_index('bug_id')[['earliest_affected_version','date_release']], on='bug_id')\n",
    "#details_myers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Combining data patience with earliest versions\n",
    "filedata_pat = pd.read_csv(analyze_dir + 'file-diff/number_of_files/patience_total_bugline.csv')\n",
    "filedata_pat = filedata_pat[['bug_id', 'filepath', 'number_of_buggyline']]\n",
    "\n",
    "details_pat = filedata_pat.join(aff.set_index('bug_id')[['earliest_affected_version','date_release']], on='bug_id')\n",
    "details_pat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start comparing buglines with the blamed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['parent_id', 'filename', 'filepath']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_hist = glob.glob(analyze_dir + 'step_3/blame_files/blame_histogram/csv/*')\n",
    "blamefiles_hist = ';'.join(filelist_hist).split(';')\n",
    "blamefiles_hist.sort()\n",
    "print (\"Found \" + str(len(blamefiles_hist)) + \" files\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filebug_hist = glob.glob(analyze_dir + 'file-diff/buggylines/histogram/*')\n",
    "diff_files_hist = ';'.join(filebug_hist).split(';')\n",
    "diff_files_hist.sort()\n",
    "print (\"Found \" + str(len(diff_files_hist)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = 2312\n",
    "print (blamefiles_hist[h])\n",
    "print (\"\\n\" + diff_files_hist[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_algo_files_hist = []\n",
    "x = 0\n",
    "while x < len(diff_files_hist):\n",
    "    sys.stdout.write(\"\\rExtracting file %i\" %(x+1))\n",
    "    sys.stdout.flush()\n",
    "    df_algo_files_hist.append([diff_files_hist[x]])\n",
    "    x += 1\n",
    "\n",
    "df_algo_files_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open csv file from result of git blame for <filename>.java\n",
    "for num, blame in enumerate(blamefiles_hist):\n",
    "    sys.stdout.write('\\rComparing bugline_files and blame_files: %i' % (num+1) + ' out of %i' % (len(blamefiles_hist)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    fields = ['line_number', 'code', 'date']\n",
    "    blamefile = pd.read_csv(blame)\n",
    "    blamefile = blamefile[fields]\n",
    "\n",
    "    origin_code = []\n",
    "    for n in range(0, len(blamefile)):\n",
    "        temp = [blamefile.iloc[n][0], str(blamefile.iloc[n][1]).replace('nan',''), blamefile.iloc[n][2]]\n",
    "        origin_code.append(temp)\n",
    "    \n",
    "    #Open diff_file <filename>.java-HBASE-xxxx_<diffalgorithm>buglines.diff vs blame_<filename>\n",
    "    for m, df in enumerate(df_algo_files_hist[num]):\n",
    "        dfname = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w.*\"), df)\n",
    "        dfname = dfname.group(0)\n",
    "        \n",
    "        diff_file = open(analyze_dir + 'file-diff/buggylines/histogram/' + dfname,'r')\n",
    "        bugline = diff_file.read().split('\\n')\n",
    "\n",
    "        if bugline[len(bugline)-1] == '':\n",
    "            for i in range(0,len(bugline)-1):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "            del bugline[len(bugline)-1]\n",
    "        else:\n",
    "            for i in range(0,len(bugline)):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "        \n",
    "        bug_id = re.compile('(HBASE-[0-9]*)')\n",
    "        bug_id = bug_id.findall(df)\n",
    "        \n",
    "        for vers in range(0,len(aff)):\n",
    "            if bug_id[0] == aff.iloc[vers][0]:\n",
    "                version = aff.iloc[vers][1]\n",
    "                daterelease = aff.iloc[vers][2]\n",
    "                break;\n",
    "            else:\n",
    "                version = 'None'\n",
    "                daterelease = 'None'\n",
    "        \n",
    "        num = 0\n",
    "        blame_compare = []\n",
    "        org_code = [el[1] for el in origin_code]\n",
    "        for y, bugs in enumerate(bugline):\n",
    "            if bugs in org_code:\n",
    "                for x in range(num, len(origin_code)):                \n",
    "                    codex = origin_code[x][1]\n",
    "                    if bugs == codex:\n",
    "                        if version != 'None':\n",
    "                            if origin_code[x][2] <= daterelease:\n",
    "                                flag = 'bug-introducing change'\n",
    "                            else:\n",
    "                                flag = 'incorrect'\n",
    "                        else:\n",
    "                            flag = 'unknown'\n",
    "                        temp = [bug_id[0], origin_code[x][0], bugs, \"True\", origin_code[x][2], version, daterelease, flag]\n",
    "                        blame_compare.append(temp)\n",
    "                        num = origin_code[x][0]\n",
    "                        break;\n",
    "            else:\n",
    "                temp = [bug_id[0], 'None', bugs, \"False\", 'None', version, daterelease, 'unknown']\n",
    "                blame_compare.append(temp)\n",
    "                #break;\n",
    "        \n",
    "        fnames = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w+[_]|(?<=histogram\\/)(\\w+[_])(?<=[_])\"), df)\n",
    "        fnames = fnames.group(0)\n",
    "        \n",
    "        #algoname = re.search((\"[_]\\w+.diff\"), df)\n",
    "        #algoname = algoname.group(0)\n",
    "        \n",
    "        blamename = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w.*\"), blame)\n",
    "        blamename = blamename.group(0)\n",
    "        \n",
    "        with open (analyze_dir + r'step_3/diff-file_blame-file_comparison/histogram_comparison/diff_' + fnames + \"histogram-\" + blamename, 'w') as csvfile:\n",
    "            writers = csv.writer(csvfile, delimiter = \",\")\n",
    "            header = ['bug_id', 'line_number', 'buggy_code', 'does_bugline_from_originfile?', 'date_added_in_originfile', 'earliest_affected_version', 'version_release_date', 'bug_class']\n",
    "            writers.writerow(header)\n",
    "            for item in blame_compare:\n",
    "                writers.writerow(item)\n",
    "                \n",
    "print ('\\nComparing buglines are complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_min = glob.glob(analyze_dir + 'step_3/blame_files/blame_minimal/csv/*')\n",
    "blamefiles_min = ';'.join(filelist_min).split(';')\n",
    "blamefiles_min.sort()\n",
    "print (\"Found \" + str(len(blamefiles_min)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filebug_min = glob.glob(analyze_dir + 'file-diff/buggylines/minimal/*')\n",
    "diff_files_min = ';'.join(filebug_min).split(';')\n",
    "diff_files_min.sort()\n",
    "print (\"Found \" + str(len(diff_files_min)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = 1763\n",
    "print (blamefiles_min[h])\n",
    "print (\"\\n\" + diff_files_min[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_algo_files_min = []\n",
    "x = 0\n",
    "while x < len(diff_files_min):\n",
    "    sys.stdout.write(\"\\rExtracting file %i\" %(x+1))\n",
    "    sys.stdout.flush()\n",
    "    df_algo_files_min.append([diff_files_min[x]])\n",
    "    x += 1\n",
    "    \n",
    "df_algo_files_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open csv file from result of git blame for <filename>.java\n",
    "for num, blame in enumerate(blamefiles_min):\n",
    "    sys.stdout.write('\\rComparing bugline_files and blame_files: %i' % (num+1) + ' out of %i' % (len(blamefiles_min)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    fields = ['line_number', 'code', 'date']\n",
    "    blamefile = pd.read_csv(blame)\n",
    "    blamefile = blamefile[fields]\n",
    "\n",
    "    origin_code = []\n",
    "    for n in range(0, len(blamefile)):\n",
    "        temp = [blamefile.iloc[n][0], str(blamefile.iloc[n][1]).replace('nan',''), blamefile.iloc[n][2]]\n",
    "        origin_code.append(temp)\n",
    "    \n",
    "    #Open diff_file <filename>.java-HBASE-xxxx_<diffalgorithm>buglines.diff vs blame_<filename>\n",
    "    for m, df in enumerate(df_algo_files_min[num]):\n",
    "        dfname = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w.*\"), df)\n",
    "        dfname = dfname.group(0)\n",
    "        \n",
    "        diff_file = open(analyze_dir + 'file-diff/buggylines/minimal/' + dfname,'r')\n",
    "        bugline = diff_file.read().split('\\n')\n",
    "\n",
    "        if bugline[len(bugline)-1] == '':\n",
    "            for i in range(0,len(bugline)-1):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "            del bugline[len(bugline)-1]\n",
    "        else:\n",
    "            for i in range(0,len(bugline)):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "        \n",
    "        bug_id = re.compile('(HBASE-[0-9]*)')\n",
    "        bug_id = bug_id.findall(df)\n",
    "        \n",
    "        for vers in range(0,len(aff)):\n",
    "            if bug_id[0] == aff.iloc[vers][0]:\n",
    "                version = aff.iloc[vers][1]\n",
    "                daterelease = aff.iloc[vers][2]\n",
    "                break;\n",
    "            else:\n",
    "                version = 'None'\n",
    "                daterelease = 'None'\n",
    "        \n",
    "        num = 0\n",
    "        blame_compare = []\n",
    "        org_code = [el[1] for el in origin_code]\n",
    "        for y, bugs in enumerate(bugline):\n",
    "            if bugs in org_code:\n",
    "                for x in range(num, len(origin_code)):                \n",
    "                    codex = origin_code[x][1]\n",
    "                    if bugs == codex:\n",
    "                        if version != 'None':\n",
    "                            if origin_code[x][2] <= daterelease:\n",
    "                                flag = 'bug-introducing change'\n",
    "                            else:\n",
    "                                flag = 'incorrect'\n",
    "                        else:\n",
    "                            flag = 'unknown'\n",
    "                        temp = [bug_id[0], origin_code[x][0], bugs, \"True\", origin_code[x][2], version, daterelease, flag]\n",
    "                        blame_compare.append(temp)\n",
    "                        num = origin_code[x][0]\n",
    "                        break;\n",
    "            else:\n",
    "                temp = [bug_id[0], 'None', bugs, \"False\", 'None', version, daterelease, 'unknown']\n",
    "                blame_compare.append(temp)\n",
    "                #break;\n",
    "        \n",
    "        fnames = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w+[_]|(?<=minimal\\/)(\\w+[_])(?<=[_])\"), df)\n",
    "        fnames = fnames.group(0)\n",
    "        \n",
    "        #algoname = re.search((\"[_]\\w+.diff\"), df)\n",
    "        #algoname = algoname.group(0)\n",
    "        \n",
    "        blamename = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w.*\"), blame)\n",
    "        blamename = blamename.group(0)\n",
    "        \n",
    "        with open (analyze_dir + r'step_3/diff-file_blame-file_comparison/minimal_comparison/diff_' + fnames + \"minimal-\" + blamename, 'w') as csvfile:\n",
    "            writers = csv.writer(csvfile, delimiter = \",\")\n",
    "            header = ['bug_id', 'line_number', 'buggy_code', 'does_bugline_from_originfile?', 'date_added_in_originfile', 'earliest_affected_version', 'version_release_date', 'bug_class']\n",
    "            writers.writerow(header)\n",
    "            for item in blame_compare:\n",
    "                writers.writerow(item)\n",
    "                \n",
    "print ('\\nComparing buglines are complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Myers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_myers = glob.glob(analyze_dir + 'step_3/blame_files/blame_myers/csv/*')\n",
    "blamefiles_myers = ';'.join(filelist_myers).split(';')\n",
    "blamefiles_myers.sort()\n",
    "print (\"Found \" + str(len(blamefiles_myers)) + \" files\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filebug_myers = glob.glob(analyze_dir + 'file-diff/buggylines/myers/*')\n",
    "diff_files_myers = ';'.join(filebug_myers).split(';')\n",
    "diff_files_myers.sort()\n",
    "print (\"Found \" + str(len(diff_files_myers)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 820\n",
    "print (blamefiles_myers[h])\n",
    "print (\"\\n\" + diff_files_myers[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_algo_files_myers = []\n",
    "x = 0\n",
    "while x < len(diff_files_myers):\n",
    "    sys.stdout.write(\"\\rExtracting file %i\" %(x+1))\n",
    "    sys.stdout.flush()\n",
    "    df_algo_files_myers.append([diff_files_myers[x]])\n",
    "    x += 1\n",
    "    \n",
    "df_algo_files_myers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open csv file from result of git blame for <filename>.java\n",
    "for num, blame in enumerate(blamefiles_myers):\n",
    "    sys.stdout.write('\\rComparing bugline_files and blame_files: %i' % (num+1) + ' out of %i' % (len(blamefiles_myers)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    fields = ['line_number', 'code', 'date']\n",
    "    blamefile = pd.read_csv(blame)\n",
    "    blamefile = blamefile[fields]\n",
    "\n",
    "    origin_code = []\n",
    "    for n in range(0, len(blamefile)):\n",
    "        temp = [blamefile.iloc[n][0], str(blamefile.iloc[n][1]).replace('nan',''), blamefile.iloc[n][2]]\n",
    "        origin_code.append(temp)\n",
    "    \n",
    "    #Open diff_file <filename>.java-HBASE-xxxx_<diffalgorithm>buglines.diff vs blame_<filename>\n",
    "    for m, df in enumerate(df_algo_files_myers[num]):\n",
    "        dfname = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w.*\"), df)\n",
    "        dfname = dfname.group(0)\n",
    "        \n",
    "        diff_file = open(analyze_dir + 'file-diff/buggylines/myers/' + dfname,'r')\n",
    "        bugline = diff_file.read().split('\\n')\n",
    "\n",
    "        if bugline[len(bugline)-1] == '':\n",
    "            for i in range(0,len(bugline)-1):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "            del bugline[len(bugline)-1]\n",
    "        else:\n",
    "            for i in range(0,len(bugline)):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "        \n",
    "        bug_id = re.compile('(HBASE-[0-9]*)')\n",
    "        bug_id = bug_id.findall(df)\n",
    "        \n",
    "        for vers in range(0,len(aff)):\n",
    "            if bug_id[0] == aff.iloc[vers][0]:\n",
    "                version = aff.iloc[vers][1]\n",
    "                daterelease = aff.iloc[vers][2]\n",
    "                break;\n",
    "            else:\n",
    "                version = 'None'\n",
    "                daterelease = 'None'\n",
    "        \n",
    "        num = 0\n",
    "        blame_compare = []\n",
    "        org_code = [el[1] for el in origin_code]\n",
    "        for y, bugs in enumerate(bugline):\n",
    "            if bugs in org_code:\n",
    "                for x in range(num, len(origin_code)):                \n",
    "                    codex = origin_code[x][1]\n",
    "                    if bugs == codex:\n",
    "                        if version != 'None':\n",
    "                            if origin_code[x][2] <= daterelease:\n",
    "                                flag = 'bug-introducing change'\n",
    "                            else:\n",
    "                                flag = 'incorrect'\n",
    "                        else:\n",
    "                            flag = 'unknown'\n",
    "                        temp = [bug_id[0], origin_code[x][0], bugs, \"True\", origin_code[x][2], version, daterelease, flag]\n",
    "                        blame_compare.append(temp)\n",
    "                        num = origin_code[x][0]\n",
    "                        break;\n",
    "            else:\n",
    "                temp = [bug_id[0], 'None', bugs, \"False\", 'None', version, daterelease, 'unknown']\n",
    "                blame_compare.append(temp)\n",
    "                #break;\n",
    "        \n",
    "        fnames = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w+[_]|(?<=myers\\/)(\\w+[_])(?<=[_])\"), df)\n",
    "        fnames = fnames.group(0)\n",
    "        \n",
    "        #algoname = re.search((\"[_]\\w+.diff\"), df)\n",
    "        #algoname = algoname.group(0)\n",
    "        \n",
    "        blamename = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w.*\"), blame)\n",
    "        blamename = blamename.group(0)\n",
    "        \n",
    "        with open (analyze_dir + r'step_3/diff-file_blame-file_comparison/myers_comparison/diff_' + fnames + \"myers-\" + blamename, 'w') as csvfile:\n",
    "            writers = csv.writer(csvfile, delimiter = \",\")\n",
    "            header = ['bug_id', 'line_number', 'buggy_code', 'does_bugline_from_originfile?', 'date_added_in_originfile', 'earliest_affected_version', 'version_release_date', 'bug_class']\n",
    "            writers.writerow(header)\n",
    "            for item in blame_compare:\n",
    "                writers.writerow(item)\n",
    "                \n",
    "print ('\\nComparing buglines are complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_pat = glob.glob(analyze_dir + 'step_3/blame_files/blame_patience/csv/*')\n",
    "blamefiles_pat = ';'.join(filelist_pat).split(';')\n",
    "blamefiles_pat.sort()\n",
    "print (\"Found \" + str(len(blamefiles_pat)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filebug_pat = glob.glob(analyze_dir + 'file-diff/buggylines/patience/*')\n",
    "diff_files_pat = ';'.join(filebug_pat).split(';')\n",
    "diff_files_pat.sort()\n",
    "print (\"Found \" + str(len(diff_files_pat)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1034\n",
    "print (blamefiles_pat[h])\n",
    "print (\"\\n\" + diff_files_pat[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_algo_files_pat = []\n",
    "x = 0\n",
    "while x < len(diff_files_pat):\n",
    "    sys.stdout.write(\"\\rExtracting file %i\" %(x+1))\n",
    "    sys.stdout.flush()\n",
    "    df_algo_files_pat.append([diff_files_pat[x]])\n",
    "    x += 1\n",
    "    \n",
    "df_algo_files_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open csv file from result of git blame for <filename>.java\n",
    "for num, blame in enumerate(blamefiles_pat):\n",
    "    sys.stdout.write('\\rComparing bugline_files and blame_files: %i' % (num+1) + ' out of %i' % (len(blamefiles_pat)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    fields = ['line_number', 'code', 'date']\n",
    "    blamefile = pd.read_csv(blame)\n",
    "    blamefile = blamefile[fields]\n",
    "\n",
    "    origin_code = []\n",
    "    for n in range(0, len(blamefile)):\n",
    "        temp = [blamefile.iloc[n][0], str(blamefile.iloc[n][1]).replace('nan',''), blamefile.iloc[n][2]]\n",
    "        origin_code.append(temp)\n",
    "    \n",
    "    #Open diff_file <filename>.java-HBASE-xxxx_<diffalgorithm>buglines.diff vs blame_<filename>\n",
    "    for m, df in enumerate(df_algo_files_pat[num]):\n",
    "        dfname = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w.*\"), df)\n",
    "        dfname = dfname.group(0)\n",
    "        \n",
    "        diff_file = open(analyze_dir + 'file-diff/buggylines/patience/' + dfname,'r')\n",
    "        bugline = diff_file.read().split('\\n')\n",
    "\n",
    "        if bugline[len(bugline)-1] == '':\n",
    "            for i in range(0,len(bugline)-1):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "            del bugline[len(bugline)-1]\n",
    "        else:\n",
    "            for i in range(0,len(bugline)):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "        \n",
    "        bug_id = re.compile('(HBASE-[0-9]*)')\n",
    "        bug_id = bug_id.findall(df)\n",
    "        \n",
    "        for vers in range(0,len(aff)):\n",
    "            if bug_id[0] == aff.iloc[vers][0]:\n",
    "                version = aff.iloc[vers][1]\n",
    "                daterelease = aff.iloc[vers][2]\n",
    "                break;\n",
    "            else:\n",
    "                version = 'None'\n",
    "                daterelease = 'None'\n",
    "        \n",
    "        num = 0\n",
    "        blame_compare = []\n",
    "        org_code = [el[1] for el in origin_code]\n",
    "        for y, bugs in enumerate(bugline):\n",
    "            if bugs in org_code:\n",
    "                for x in range(num, len(origin_code)):                \n",
    "                    codex = origin_code[x][1]\n",
    "                    if bugs == codex:\n",
    "                        if version != 'None':\n",
    "                            if origin_code[x][2] <= daterelease:\n",
    "                                flag = 'bug-introducing change'\n",
    "                            else:\n",
    "                                flag = 'incorrect'\n",
    "                        else:\n",
    "                            flag = 'unknown'\n",
    "                        temp = [bug_id[0], origin_code[x][0], bugs, \"True\", origin_code[x][2], version, daterelease, flag]\n",
    "                        blame_compare.append(temp)\n",
    "                        num = origin_code[x][0]\n",
    "                        break;\n",
    "            else:\n",
    "                temp = [bug_id[0], 'None', bugs, \"False\", 'None', version, daterelease, 'unknown']\n",
    "                blame_compare.append(temp)\n",
    "                #break;\n",
    "        \n",
    "        fnames = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w+[_]|(?<=patience\\/)(\\w+[_])(?<=[_])\"), df)\n",
    "        fnames = fnames.group(0)\n",
    "        \n",
    "        #algoname = re.search((\"[_]\\w+.diff\"), df)\n",
    "        #algoname = algoname.group(0)\n",
    "        \n",
    "        blamename = re.search((\"(?:\\w+[-]\\w+[-]\\w+|\\w+[-]\\w+|\\w+)[.]\\w.*\"), blame)\n",
    "        blamename = blamename.group(0)\n",
    "        \n",
    "        with open (analyze_dir + r'step_3/diff-file_blame-file_comparison/patience_comparison/diff_' + fnames + \"patience-\" + blamename, 'w') as csvfile:\n",
    "            writers = csv.writer(csvfile, delimiter = \",\")\n",
    "            header = ['bug_id', 'line_number', 'buggy_code', 'does_bugline_from_originfile?', 'date_added_in_originfile', 'earliest_affected_version', 'version_release_date', 'bug_class']\n",
    "            writers.writerow(header)\n",
    "            for item in blame_compare:\n",
    "                writers.writerow(item)\n",
    "                \n",
    "print ('\\nComparing buglines are complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
