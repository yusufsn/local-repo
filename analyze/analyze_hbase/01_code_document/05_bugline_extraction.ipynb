{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, json, csv, subprocess, sys, re, operator\n",
    "from git import *\n",
    "from subprocess import Popen, PIPE\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as ply\n",
    "import plotly\n",
    "from plotly.offline import plot, init_notebook_mode, iplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining repository and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userhome = os.path.expanduser('~')\n",
    "repository = userhome + r'/different-diff/dataset/openjpa/'\n",
    "analyze_dir = userhome + r'/different-diff/analyze/analyze_openjpa/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining function to execute git command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_command(cmd, work_dir):\n",
    "   #Executes a shell command in a subprocess, waiting until it has completed.\n",
    "    pipe = subprocess.Popen(cmd, shell=True, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    (out, error) = pipe.communicate()\n",
    "    return out, error\n",
    "    pipe.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms = ['histogram','minimal','myers','patience']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the files data for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fields = ['bug_id','bugintro_commitID','parent_id','filename','#deletions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dthist = pd.read_csv(analyze_dir + '03_file-diff/01_filename/histogram_files.csv')\n",
    "dtmin = pd.read_csv(analyze_dir + '03_file-diff/01_filename/minimal_files.csv')\n",
    "dtmyers = pd.read_csv(analyze_dir + '03_file-diff/01_filename/myers_files.csv')\n",
    "dtpat = pd.read_csv(analyze_dir + '03_file-diff/01_filename/patience_files.csv')\n",
    "\n",
    "dthist = dthist[fields]\n",
    "dtmin = dtmin[fields]\n",
    "dtmyers = dtmyers[fields]\n",
    "dtpat = dtpat[fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dthist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_algorithm = [dthist, dtmin, dtmyers, dtpat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating txt files of filenames list for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for da, dt_alg in enumerate(data_algorithm):\n",
    "    filename = []\n",
    "    for jj in range(0,len(dt_alg)):\n",
    "        if dt_alg.iloc[jj]['#deletions'] != 0:\n",
    "            filename.append(\"_\" + ((dt_alg.iloc[jj][3].split('/'))[-1:])[0] + \"_\"+ dt_alg.iloc[jj][1] + \"-\" + dt_alg.iloc[jj][2][:10] + \"_\" + dt_alg.iloc[jj][0] + \"_\" + str(jj+1))\n",
    "\n",
    "    with open(analyze_dir + '03_file-diff/01_filename/filename-listof_'+ algorithms[da] + '.txt', mode='wt', encoding=\"utf-8\") as myfile:\n",
    "        myfile.write('\\n'.join(filename))\n",
    "\n",
    "print (\"Filename_<algorithm-name>.txt has been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the buggylines of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading txt filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_hist = (open(analyze_dir + '03_file-diff/01_filename/filename-listof_histogram.txt')).read().split('\\n')\n",
    "fn_min = (open(analyze_dir + '03_file-diff/01_filename/filename-listof_minimal.txt')).read().split('\\n')\n",
    "fn_myers = (open(analyze_dir + '03_file-diff/01_filename/filename-listof_myers.txt')).read().split('\\n')\n",
    "fn_pat = (open(analyze_dir + '03_file-diff/01_filename/filename-listof_patience.txt')).read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_names = [fn_hist, fn_min, fn_myers, fn_pat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buggylines extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buggylinefiles = []\n",
    "for n, d_algo in enumerate(data_algorithm):\n",
    "    bf = []\n",
    "    for aa in range(0,len(d_algo)):\n",
    "        sys.stdout.write('\\r%i: ' %(n+1) + ' Extracting data %i' %(aa+1))\n",
    "        sys.stdout.flush()\n",
    "        name = analyze_dir + \"03_file-diff/02_buggylines/\" + algorithms[n] + \"/\" + f_names[n][aa] + \"_\" + algorithms[n] + \"buglines_\" + str(aa+1) + \".diff\"\n",
    "        diff_cmd = \"git diff -w --ignore-blank-lines --diff-algorithm=\" + algorithms[n] + \" \" + d_algo.iloc[aa][2] + \" \" + d_algo.iloc[aa][1] + \" -- \" + d_algo.iloc[aa][3] + \" | grep '^[-]' | grep -Ev '^(--- a/|\\+\\+\\+ b/)' > \" + name\n",
    "        execute_command(diff_cmd, repository)\n",
    "        zzz = [d_algo.iloc[aa][0], d_algo.iloc[aa][1], d_algo.iloc[aa][2], d_algo.iloc[aa][3], (f_names[n][aa] + \"_\" + algorithms[n] + \"buglines_\" + str(aa+1) + \".diff\")]\n",
    "        bf.append(zzz)\n",
    "    bf = sorted(bf, key=operator.itemgetter(4,1,2,0))\n",
    "    buggylinefiles.append(bf)\n",
    "print('\\nExtraction is complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buggylinefiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading files of buggylines for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_file = []\n",
    "for m, algrt in enumerate(algorithms):\n",
    "    temp_file = []\n",
    "    s = 0\n",
    "    for f_name in glob.iglob(analyze_dir + '03_file-diff/02_buggylines/' + algrt + '/*', recursive=True):\n",
    "        sys.stdout.write(\"\\r%i \" %(m+1) + \"Counting bugline for file %i\" %(s+1))\n",
    "        sys.stdout.flush()\n",
    "        s += 1\n",
    "        \n",
    "        temp_file.append(f_name)\n",
    "    temp_file.sort()\n",
    "    bug_file.append(temp_file)\n",
    "print (\"\\nReading files are complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting number of files and number of buggylines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing files with no deletion changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devs = []\n",
    "for n, algr in enumerate(algorithms):\n",
    "    total = []\n",
    "    dev = []\n",
    "    for rr, f_name in enumerate(bug_file[n]):\n",
    "        sys.stdout.write(\"\\r%i \" %(n+1) + \"Counting bugline for file %i\" %(rr+1))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        fn = open(f_name, encoding=\"utf8\", errors='ignore')\n",
    "        fn = fn.read().split('\\n')\n",
    "        if \"--- /dev\" in fn[0]:\n",
    "            num = str(len(fn)-2)\n",
    "        else:\n",
    "            num = str(len(fn)-1)\n",
    "        \n",
    "        pattern = re.search(\"((?<=\" + algr + \"\\/)_.\\w+[a-zA-Z0-9-.]+(?=_[a-z0-9]))\", f_name)\n",
    "        pattern = pattern.group()[1:]\n",
    "        \n",
    "        if num != '0':\n",
    "            current = [buggylinefiles[n][rr][0], buggylinefiles[n][rr][1], buggylinefiles[n][rr][2], buggylinefiles[n][rr][3], pattern, num]\n",
    "            total.append(current)\n",
    "    \n",
    "    total = sorted(total, key=operator.itemgetter(4,1,2,0))\n",
    "    \n",
    "    with open(analyze_dir + \"03_file-diff/03_number_of_files/\" + algr + \"_total_bugline.csv\", 'w') as myfile:\n",
    "        writers = csv.writer(myfile)\n",
    "        fields = ['bug_id','bugintro_commitID','parent_id','filepath','filename','number_of_buggyline']\n",
    "        writers.writerow(fields)\n",
    "        for row in total:\n",
    "            writers.writerow(row)\n",
    "            \n",
    "print (\"\\nCounting buggylines are complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading files total_bugline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_totalhist = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/histogram_total_bugline.csv')\n",
    "df_totalmin = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/minimal_total_bugline.csv')\n",
    "df_totalmyers = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/myers_total_bugline.csv')\n",
    "df_totalpat = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/patience_total_bugline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping same files and sum of the number of buglines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_frame = [df_totalhist, df_totalmin, df_totalmyers, df_totalpat]\n",
    "for d, dfr in enumerate(d_frame):\n",
    "    dframe = (pd.to_numeric(dfr['number_of_buggyline'], errors='coerce')\n",
    "           .groupby(dfr['filepath'])\n",
    "           .sum()\n",
    "           .to_frame()\n",
    "           .add_prefix('total')\n",
    "           .reset_index())\n",
    "\n",
    "    col = ['filepath','totalnumber_of_buggyline']\n",
    "    dframe = dframe.dropna(subset=['totalnumber_of_buggyline'])\n",
    "    dframe = dframe.sort_values('totalnumber_of_buggyline', ascending=False)\n",
    "\n",
    "    dframe[col].to_csv(analyze_dir + '03_file-diff/03_number_of_files/totalbug_of_' + algorithms[d] + '_filechanged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminating files with zero total number of buggyline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfrhist = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/totalbug_of_histogram_filechanged.csv')\n",
    "dfrmin = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/totalbug_of_minimal_filechanged.csv')\n",
    "dfrmyers = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/totalbug_of_myers_filechanged.csv')\n",
    "dfrpat = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/totalbug_of_patience_filechanged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating zero buggyline files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['filepath','totalnumber_of_buggyline']\n",
    "filehist = dfrhist[cols][dfrhist['totalnumber_of_buggyline'] != 0]\n",
    "filemin = dfrmin[cols][dfrmin['totalnumber_of_buggyline'] != 0]\n",
    "filemyers = dfrmyers[cols][dfrmyers['totalnumber_of_buggyline'] != 0]\n",
    "filepat = dfrpat[cols][dfrpat['totalnumber_of_buggyline'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filehist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filehist.to_csv(analyze_dir + '03_file-diff/03_number_of_files/01_files_with_buglines/histogramfiles_with_buglines.csv')\n",
    "filemin.to_csv(analyze_dir + '03_file-diff/03_number_of_files/01_files_with_buglines/minimalfiles_with_buglines.csv')\n",
    "filemyers.to_csv(analyze_dir + '03_file-diff/03_number_of_files/01_files_with_buglines/myersfiles_with_buglines.csv')\n",
    "filepat.to_csv(analyze_dir + '03_file-diff/03_number_of_files/01_files_with_buglines/patiencefiles_with_buglines.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = []\n",
    "for n, algr in enumerate(algorithms):\n",
    "    file = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/01_files_with_buglines/' + algr + 'files_with_buglines.csv')\n",
    "    file = file[cols]\n",
    "    numfile = len(file)\n",
    "    totbug = file['totalnumber_of_buggyline'].sum()\n",
    "    temp = [algr, numfile, totbug]\n",
    "    stat.append(temp)\n",
    "print (\"Counting files and number of buglines are complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(analyze_dir + '03_file-diff/03_number_of_files/01_files_with_buglines/file_and_bug-stats.csv','w') as statfile:\n",
    "    column = ['algorithm', 'number_of_files', 'totalnumber_of_buglines']\n",
    "    writers = csv.writer(statfile, delimiter=',')\n",
    "    writers.writerow(column)\n",
    "    for item in stat:\n",
    "        writers.writerow(item)\n",
    "    \n",
    "stats = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/01_files_with_buglines/file_and_bug-stats.csv')\n",
    "stats = stats[column]\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing total number of buglines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing number of files and total number of buglines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numfiles = go.Bar(\n",
    "    x = stats['algorithm'],\n",
    "    y = stats['number_of_files'],\n",
    "    text = stats['number_of_files'],\n",
    "    textposition = 'auto',\n",
    "    opacity = 0.6,\n",
    "    marker = dict(\n",
    "        color = 'rgb(150,255,200)',\n",
    "        line = dict(\n",
    "            color='rgb(8,48,107)',\n",
    "            width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "dtbar = [numfiles]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Number of files changed in PIG Project'\n",
    ")\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "fig = go.Figure(data=dtbar, layout=layout)\n",
    "iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totbug = go.Bar(\n",
    "    x = stats['algorithm'],\n",
    "    y = stats['totalnumber_of_buglines'],\n",
    "    text = stats['totalnumber_of_buglines'],\n",
    "    textposition = 'auto',\n",
    "    name = 'Number of buglines',\n",
    "    opacity = 0.6,\n",
    "    marker = dict(\n",
    "        color = 'rgb(150,255,200)',\n",
    "        line = dict(\n",
    "            color='rgb(8,48,107)',\n",
    "            width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "dtbar = [totbug]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Total number of buglines in PIG Project'\n",
    ")\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "fig = go.Figure(data=dtbar, layout=layout)\n",
    "iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
