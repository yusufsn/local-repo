{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, json, csv, subprocess, sys, re\n",
    "from git import *\n",
    "from subprocess import Popen, PIPE\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining repository and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userhome = os.path.expanduser(\"~\")\n",
    "repository = userhome + r\"/different-diff/dataset/openjpa/\"\n",
    "analyze_dir = userhome + r'/different-diff/analyze/analyze_openjpa/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the earliest affected versions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "affected_version = pd.read_csv(analyze_dir + '05_finding_versions/01_affected_version/earliest_version.csv')\n",
    "cols = ['bug_id','earliest_affected_version','date_release']\n",
    "aff = affected_version[cols]\n",
    "aff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining buggyfile data with the earliest versions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms = ['histogram','minimal','myers','patience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colname = ['bug_id','bugintro_commitID','parent_id','filepath','number_of_buggyline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining data with earliest versions\n",
    "for xx, algr in enumerate(algorithms):\n",
    "    filedata = pd.read_csv(analyze_dir + '03_file-diff/03_number_of_files/' + algr + '_total_bugline.csv')\n",
    "    filedata = filedata[colname]\n",
    "\n",
    "    details = filedata.join(aff.set_index('bug_id')[['earliest_affected_version','date_release']], on='bug_id')\n",
    "    details.to_csv(analyze_dir + '05_finding_versions/01_affected_version/affected_version_for_' + algr + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start comparing buglines with the blamed files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_hist = glob.glob(analyze_dir + '04_annotate/01_blame_files/blame_histogram/csv/*')\n",
    "blamefiles_hist = ';'.join(filelist_hist).split(';')\n",
    "blamefiles_hist.sort()\n",
    "print (\"Found \" + str(len(blamefiles_hist)) + \" files\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_files_hist = []\n",
    "for files in glob.iglob(analyze_dir + \"03_file-diff/02_buggylines/histogram/*\"):\n",
    "    fn = open(files, encoding=\"utf8\", errors='ignore')\n",
    "    fn = fn.read().split('\\n')\n",
    "    \n",
    "    if \"--- /dev/null\" not in fn[0]:\n",
    "        if fn[0] != '':\n",
    "            diff_files_hist.append(files)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "diff_files_hist.sort()\n",
    "print (\"Found \" + str(len(diff_files_hist)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 850\n",
    "print (blamefiles_hist[h])\n",
    "print (\"\\n\" + diff_files_hist[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_algo_files_hist = []\n",
    "x = 0\n",
    "while x < len(diff_files_hist):\n",
    "    sys.stdout.write(\"\\rExtracting file %i\" %(x+1))\n",
    "    sys.stdout.flush()\n",
    "    df_algo_files_hist.append([diff_files_hist[x]])\n",
    "    x += 1\n",
    "\n",
    "df_algo_files_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open csv file from result of git blame for <filename>.java\n",
    "for num, blame in enumerate(blamefiles_hist):\n",
    "    sys.stdout.write('\\rComparing bugline_files and blame_files: %i' % (num+1) + ' out of %i' % (len(blamefiles_hist)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    fields = ['line_number', 'code', 'date']\n",
    "    blamefile = pd.read_csv(blame)\n",
    "    blamefile = blamefile[fields]\n",
    "\n",
    "    origin_code = []\n",
    "    for n in range(0, len(blamefile)):\n",
    "        temp = [blamefile.iloc[n][0], str(blamefile.iloc[n][1]).replace('nan',''), blamefile.iloc[n][2]]\n",
    "        origin_code.append(temp)\n",
    "    \n",
    "    #Open diff_file <filename>.java-HBASE-xxxx_<diffalgorithm>buglines.diff vs blame_<filename>\n",
    "    for m, df in enumerate(df_algo_files_hist[num]):\n",
    "        dfname = re.search((\"(?<=histogram\\/)\\w.*\"), df)\n",
    "        dfname = dfname.group(0)\n",
    "        \n",
    "        diff_file = open(analyze_dir + '03_file-diff/02_buggylines/histogram/' + dfname, encoding=\"utf8\", errors='ignore')\n",
    "        bugline = diff_file.read().split('\\n')\n",
    "\n",
    "        if bugline[len(bugline)-1] == '':\n",
    "            for i in range(0,len(bugline)-1):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "            del bugline[len(bugline)-1]\n",
    "        else:\n",
    "            for i in range(0,len(bugline)):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "        \n",
    "        bug_id = re.compile('(OPENJPA-[0-9]*)')\n",
    "        bug_id = bug_id.findall(df)\n",
    "        \n",
    "        for vers in range(0,len(aff)):\n",
    "            if bug_id[0] == aff.iloc[vers][0]:\n",
    "                version = aff.iloc[vers][1]\n",
    "                daterelease = aff.iloc[vers][2]\n",
    "                break;\n",
    "            else:\n",
    "                version = 'None'\n",
    "                daterelease = 'None'\n",
    "        \n",
    "        num = 0\n",
    "        blame_compare = []\n",
    "        org_code = [el[1] for el in origin_code]\n",
    "        for y, bugs in enumerate(bugline):\n",
    "            if bugs in org_code:\n",
    "                for x in range(num, len(origin_code)):                \n",
    "                    codex = origin_code[x][1]\n",
    "                    if bugs == codex:\n",
    "                        if version != 'None':\n",
    "                            if origin_code[x][2] <= daterelease:\n",
    "                                flag = 'bug-introducing change'\n",
    "                            else:\n",
    "                                flag = 'incorrect'\n",
    "                        else:\n",
    "                            flag = 'unknown'\n",
    "                        temp = [bug_id[0], origin_code[x][0], bugs, \"True\", origin_code[x][2], version, daterelease, flag]\n",
    "                        blame_compare.append(temp)\n",
    "                        num = origin_code[x][0]\n",
    "                        break;\n",
    "            else:\n",
    "                temp = [bug_id[0], 'None', bugs, \"False\", 'None', version, daterelease, 'unknown']\n",
    "                blame_compare.append(temp)\n",
    "                #break;\n",
    "        \n",
    "        fnames = re.search((\"((?<=histogram\\/\\_).[a-zA-Z0-9-.]+(?=_))\"), df)\n",
    "        fnames = fnames.group(0)\n",
    "        \n",
    "        #algoname = re.search((\"[_]\\w+.diff\"), df)\n",
    "        #algoname = algoname.group(0)\n",
    "        \n",
    "        blamename = re.search((\"(?<=\\/csv\\/)(?:\\w.*)\"), blame)\n",
    "        blamename = blamename.group(0)\n",
    "        \n",
    "        with open (analyze_dir + r'04_annotate/02_diff-file_blame-file_comparison/histogram_comparison/diff_' + fnames + \"_histogram-\" + blamename, 'w') as csvfile:\n",
    "            writers = csv.writer(csvfile, delimiter = \",\")\n",
    "            header = ['bug_id', 'line_number', 'buggy_code', 'does_bugline_from_originfile?', 'date_added_in_originfile', 'earliest_affected_version', 'version_release_date', 'bug_class']\n",
    "            writers.writerow(header)\n",
    "            for item in blame_compare:\n",
    "                writers.writerow(item)\n",
    "                \n",
    "print ('\\nComparing buglines are complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_min = glob.glob(analyze_dir + '04_annotate/01_blame_files/blame_minimal/csv/*')\n",
    "blamefiles_min = ';'.join(filelist_min).split(';')\n",
    "blamefiles_min.sort()\n",
    "print (\"Found \" + str(len(blamefiles_min)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_files_min = []\n",
    "for files in glob.iglob(analyze_dir + \"03_file-diff/02_buggylines/minimal/*\"):\n",
    "    fn = open(files, encoding=\"utf8\", errors='ignore')\n",
    "    fn = fn.read().split('\\n')\n",
    "    \n",
    "    if \"--- /dev/null\" not in fn[0]:\n",
    "        if fn[0] != '':\n",
    "            diff_files_min.append(files)\n",
    "    else:\n",
    "        pass\n",
    "diff_files_min.sort()\n",
    "print (\"Found \" + str(len(diff_files_min)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 345\n",
    "print (blamefiles_min[h])\n",
    "print (\"\\n\" + diff_files_min[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_algo_files_min = []\n",
    "x = 0\n",
    "while x < len(diff_files_min):\n",
    "    sys.stdout.write(\"\\rExtracting file %i\" %(x+1))\n",
    "    sys.stdout.flush()\n",
    "    df_algo_files_min.append([diff_files_min[x]])\n",
    "    x += 1\n",
    "    \n",
    "df_algo_files_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open csv file from result of git blame for <filename>.java\n",
    "for num, blame in enumerate(blamefiles_min):\n",
    "    sys.stdout.write('\\rComparing bugline_files and blame_files: %i' % (num+1) + ' out of %i' % (len(blamefiles_min)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    fields = ['line_number', 'code', 'date']\n",
    "    blamefile = pd.read_csv(blame)\n",
    "    blamefile = blamefile[fields]\n",
    "\n",
    "    origin_code = []\n",
    "    for n in range(0, len(blamefile)):\n",
    "        temp = [blamefile.iloc[n][0], str(blamefile.iloc[n][1]).replace('nan',''), blamefile.iloc[n][2]]\n",
    "        origin_code.append(temp)\n",
    "    \n",
    "    #Open diff_file <filename>.java-HBASE-xxxx_<diffalgorithm>buglines.diff vs blame_<filename>\n",
    "    for m, df in enumerate(df_algo_files_min[num]):\n",
    "        dfname = re.search((\"(?<=minimal\\/)\\w.*\"), df)\n",
    "        dfname = dfname.group(0)\n",
    "        \n",
    "        diff_file = open(analyze_dir + '03_file-diff/02_buggylines/minimal/' + dfname, encoding=\"utf8\", errors='ignore')\n",
    "        bugline = diff_file.read().split('\\n')\n",
    "\n",
    "        if bugline[len(bugline)-1] == '':\n",
    "            for i in range(0,len(bugline)-1):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "            del bugline[len(bugline)-1]\n",
    "        else:\n",
    "            for i in range(0,len(bugline)):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "        \n",
    "        bug_id = re.compile('(OPENJPA-[0-9]*)')\n",
    "        bug_id = bug_id.findall(df)\n",
    "        \n",
    "        for vers in range(0,len(aff)):\n",
    "            if bug_id[0] == aff.iloc[vers][0]:\n",
    "                version = aff.iloc[vers][1]\n",
    "                daterelease = aff.iloc[vers][2]\n",
    "                break;\n",
    "            else:\n",
    "                version = 'None'\n",
    "                daterelease = 'None'\n",
    "        \n",
    "        num = 0\n",
    "        blame_compare = []\n",
    "        org_code = [el[1] for el in origin_code]\n",
    "        for y, bugs in enumerate(bugline):\n",
    "            if bugs in org_code:\n",
    "                for x in range(num, len(origin_code)):                \n",
    "                    codex = origin_code[x][1]\n",
    "                    if bugs == codex:\n",
    "                        if version != 'None':\n",
    "                            if origin_code[x][2] <= daterelease:\n",
    "                                flag = 'bug-introducing change'\n",
    "                            else:\n",
    "                                flag = 'incorrect'\n",
    "                        else:\n",
    "                            flag = 'unknown'\n",
    "                        temp = [bug_id[0], origin_code[x][0], bugs, \"True\", origin_code[x][2], version, daterelease, flag]\n",
    "                        blame_compare.append(temp)\n",
    "                        num = origin_code[x][0]\n",
    "                        break;\n",
    "            else:\n",
    "                temp = [bug_id[0], 'None', bugs, \"False\", 'None', version, daterelease, 'unknown']\n",
    "                blame_compare.append(temp)\n",
    "                #break;\n",
    "        \n",
    "        fnames = re.search((\"((?<=minimal\\/\\_).[a-zA-Z0-9-.]+(?=_))\"), df)\n",
    "        fnames = fnames.group(0)\n",
    "        \n",
    "        #algoname = re.search((\"[_]\\w+.diff\"), df)\n",
    "        #algoname = algoname.group(0)\n",
    "        \n",
    "        blamename = re.search((\"(?<=\\/csv\\/)(?:\\w.*)\"), blame)\n",
    "        blamename = blamename.group(0)\n",
    "        \n",
    "        with open (analyze_dir + r'04_annotate/02_diff-file_blame-file_comparison/minimal_comparison/diff_' + fnames + \"_minimal-\" + blamename, 'w') as csvfile:\n",
    "            writers = csv.writer(csvfile, delimiter = \",\")\n",
    "            header = ['bug_id', 'line_number', 'buggy_code', 'does_bugline_from_originfile?', 'date_added_in_originfile', 'earliest_affected_version', 'version_release_date', 'bug_class']\n",
    "            writers.writerow(header)\n",
    "            for item in blame_compare:\n",
    "                writers.writerow(item)\n",
    "                \n",
    "print ('\\nComparing buglines are complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Myers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_myers = glob.glob(analyze_dir + '04_annotate/01_blame_files/blame_myers/csv/*')\n",
    "blamefiles_myers = ';'.join(filelist_myers).split(';')\n",
    "blamefiles_myers.sort()\n",
    "print (\"Found \" + str(len(blamefiles_myers)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_files_myers = []\n",
    "for files in glob.iglob(analyze_dir + \"03_file-diff/02_buggylines/myers/*\"):\n",
    "    fn = open(files, encoding=\"utf8\", errors='ignore')\n",
    "    fn = fn.read().split('\\n')\n",
    "    \n",
    "    if \"--- /dev/null\" not in fn[0]:\n",
    "        if fn[0] != '':\n",
    "            diff_files_myers.append(files)\n",
    "    else:\n",
    "        pass\n",
    "diff_files_myers.sort()\n",
    "print (\"Found \" + str(len(diff_files_myers)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 24\n",
    "print (blamefiles_myers[h])\n",
    "print (\"\\n\" + diff_files_myers[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_algo_files_myers = []\n",
    "x = 0\n",
    "while x < len(diff_files_myers):\n",
    "    sys.stdout.write(\"\\rExtracting file %i\" %(x+1))\n",
    "    sys.stdout.flush()\n",
    "    df_algo_files_myers.append([diff_files_myers[x]])\n",
    "    x += 1\n",
    "    \n",
    "df_algo_files_myers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open csv file from result of git blame for <filename>.java\n",
    "for num, blame in enumerate(blamefiles_myers):\n",
    "    sys.stdout.write('\\rComparing bugline_files and blame_files: %i' % (num+1) + ' out of %i' % (len(blamefiles_myers)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    fields = ['line_number', 'code', 'date']\n",
    "    blamefile = pd.read_csv(blame)\n",
    "    blamefile = blamefile[fields]\n",
    "\n",
    "    origin_code = []\n",
    "    for n in range(0, len(blamefile)):\n",
    "        temp = [blamefile.iloc[n][0], str(blamefile.iloc[n][1]).replace('nan',''), blamefile.iloc[n][2]]\n",
    "        origin_code.append(temp)\n",
    "    \n",
    "    #Open diff_file <filename>.java-HBASE-xxxx_<diffalgorithm>buglines.diff vs blame_<filename>\n",
    "    for m, df in enumerate(df_algo_files_myers[num]):\n",
    "        dfname = re.search((\"(?<=myers\\/)\\w.*\"), df)\n",
    "        dfname = dfname.group(0)\n",
    "        \n",
    "        diff_file = open(analyze_dir + '03_file-diff/02_buggylines/myers/' + dfname, encoding=\"utf8\", errors='ignore')\n",
    "        bugline = diff_file.read().split('\\n')\n",
    "\n",
    "        if bugline[len(bugline)-1] == '':\n",
    "            for i in range(0,len(bugline)-1):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "            del bugline[len(bugline)-1]\n",
    "        else:\n",
    "            for i in range(0,len(bugline)):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "        \n",
    "        bug_id = re.compile('(OPENJPA-[0-9]*)')\n",
    "        bug_id = bug_id.findall(df)\n",
    "        \n",
    "        for vers in range(0,len(aff)):\n",
    "            if bug_id[0] == aff.iloc[vers][0]:\n",
    "                version = aff.iloc[vers][1]\n",
    "                daterelease = aff.iloc[vers][2]\n",
    "                break;\n",
    "            else:\n",
    "                version = 'None'\n",
    "                daterelease = 'None'\n",
    "        \n",
    "        num = 0\n",
    "        blame_compare = []\n",
    "        org_code = [el[1] for el in origin_code]\n",
    "        for y, bugs in enumerate(bugline):\n",
    "            if bugs in org_code:\n",
    "                for x in range(num, len(origin_code)):                \n",
    "                    codex = origin_code[x][1]\n",
    "                    if bugs == codex:\n",
    "                        if version != 'None':\n",
    "                            if origin_code[x][2] <= daterelease:\n",
    "                                flag = 'bug-introducing change'\n",
    "                            else:\n",
    "                                flag = 'incorrect'\n",
    "                        else:\n",
    "                            flag = 'unknown'\n",
    "                        temp = [bug_id[0], origin_code[x][0], bugs, \"True\", origin_code[x][2], version, daterelease, flag]\n",
    "                        blame_compare.append(temp)\n",
    "                        num = origin_code[x][0]\n",
    "                        break;\n",
    "            else:\n",
    "                temp = [bug_id[0], 'None', bugs, \"False\", 'None', version, daterelease, 'unknown']\n",
    "                blame_compare.append(temp)\n",
    "                #break;\n",
    "        \n",
    "        fnames = re.search((\"((?<=myers\\/\\_).[a-zA-Z0-9-.]+(?=_))\"), df)\n",
    "        fnames = fnames.group(0)\n",
    "        \n",
    "        #algoname = re.search((\"[_]\\w+.diff\"), df)\n",
    "        #algoname = algoname.group(0)\n",
    "        \n",
    "        blamename = re.search((\"(?<=\\/csv\\/)(?:\\w.*)\"), blame)\n",
    "        blamename = blamename.group(0)\n",
    "        \n",
    "        with open (analyze_dir + r'04_annotate/02_diff-file_blame-file_comparison/myers_comparison/diff_' + fnames + \"_myers-\" + blamename, 'w') as csvfile:\n",
    "            writers = csv.writer(csvfile, delimiter = \",\")\n",
    "            header = ['bug_id', 'line_number', 'buggy_code', 'does_bugline_from_originfile?', 'date_added_in_originfile', 'earliest_affected_version', 'version_release_date', 'bug_class']\n",
    "            writers.writerow(header)\n",
    "            for item in blame_compare:\n",
    "                writers.writerow(item)\n",
    "                \n",
    "print ('\\nComparing buglines are complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_pat = glob.glob(analyze_dir + '04_annotate/01_blame_files/blame_patience/csv/*')\n",
    "blamefiles_pat = ';'.join(filelist_pat).split(';')\n",
    "blamefiles_pat.sort()\n",
    "print (\"Found \" + str(len(blamefiles_pat)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_files_pat = []\n",
    "for files in glob.iglob(analyze_dir + \"03_file-diff/02_buggylines/patience/*\"):\n",
    "    fn = open(files, encoding=\"utf8\", errors='ignore')\n",
    "    fn = fn.read().split('\\n')\n",
    "    \n",
    "    if \"--- /dev/null\" not in fn[0]:\n",
    "        if fn[0] != '':\n",
    "            diff_files_pat.append(files)\n",
    "    else:\n",
    "        pass\n",
    "diff_files_pat.sort()\n",
    "print (\"Found \" + str(len(diff_files_pat)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 601\n",
    "print (blamefiles_pat[h])\n",
    "print (\"\\n\" + diff_files_pat[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_algo_files_pat = []\n",
    "x = 0\n",
    "while x < len(diff_files_pat):\n",
    "    sys.stdout.write(\"\\rExtracting file %i\" %(x+1))\n",
    "    sys.stdout.flush()\n",
    "    df_algo_files_pat.append([diff_files_pat[x]])\n",
    "    x += 1\n",
    "    \n",
    "df_algo_files_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open csv file from result of git blame for <filename>.java\n",
    "for num, blame in enumerate(blamefiles_pat):\n",
    "    sys.stdout.write('\\rComparing bugline_files and blame_files: %i' % (num+1) + ' out of %i' % (len(blamefiles_pat)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    fields = ['line_number', 'code', 'date']\n",
    "    blamefile = pd.read_csv(blame)\n",
    "    blamefile = blamefile[fields]\n",
    "\n",
    "    origin_code = []\n",
    "    for n in range(0, len(blamefile)):\n",
    "        temp = [blamefile.iloc[n][0], str(blamefile.iloc[n][1]).replace('nan',''), blamefile.iloc[n][2]]\n",
    "        origin_code.append(temp)\n",
    "    \n",
    "    #Open diff_file <filename>.java-HBASE-xxxx_<diffalgorithm>buglines.diff vs blame_<filename>\n",
    "    for m, df in enumerate(df_algo_files_pat[num]):\n",
    "        dfname = re.search((\"(?<=patience\\/)\\w.*\"), df)\n",
    "        dfname = dfname.group(0)\n",
    "        \n",
    "        diff_file = open(analyze_dir + '03_file-diff/02_buggylines/patience/' + dfname, encoding=\"utf8\", errors='ignore')\n",
    "        bugline = diff_file.read().split('\\n')\n",
    "\n",
    "        if bugline[len(bugline)-1] == '':\n",
    "            for i in range(0,len(bugline)-1):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "            del bugline[len(bugline)-1]\n",
    "        else:\n",
    "            for i in range(0,len(bugline)):\n",
    "                bugline[i] = bugline[i][1:]\n",
    "        \n",
    "        bug_id = re.compile('(OPENJPA-[0-9]*)')\n",
    "        bug_id = bug_id.findall(df)\n",
    "        \n",
    "        for vers in range(0,len(aff)):\n",
    "            if bug_id[0] == aff.iloc[vers][0]:\n",
    "                version = aff.iloc[vers][1]\n",
    "                daterelease = aff.iloc[vers][2]\n",
    "                break;\n",
    "            else:\n",
    "                version = 'None'\n",
    "                daterelease = 'None'\n",
    "        \n",
    "        num = 0\n",
    "        blame_compare = []\n",
    "        org_code = [el[1] for el in origin_code]\n",
    "        for y, bugs in enumerate(bugline):\n",
    "            if bugs in org_code:\n",
    "                for x in range(num, len(origin_code)):                \n",
    "                    codex = origin_code[x][1]\n",
    "                    if bugs == codex:\n",
    "                        if version != 'None':\n",
    "                            if origin_code[x][2] <= daterelease:\n",
    "                                flag = 'bug-introducing change'\n",
    "                            else:\n",
    "                                flag = 'incorrect'\n",
    "                        else:\n",
    "                            flag = 'unknown'\n",
    "                        temp = [bug_id[0], origin_code[x][0], bugs, \"True\", origin_code[x][2], version, daterelease, flag]\n",
    "                        blame_compare.append(temp)\n",
    "                        num = origin_code[x][0]\n",
    "                        break;\n",
    "            else:\n",
    "                temp = [bug_id[0], 'None', bugs, \"False\", 'None', version, daterelease, 'unknown']\n",
    "                blame_compare.append(temp)\n",
    "                #break;\n",
    "        \n",
    "        fnames = re.search((\"((?<=patience\\/\\_).[a-zA-Z0-9-.]+(?=_))\"), df)\n",
    "        fnames = fnames.group(0)\n",
    "        \n",
    "        #algoname = re.search((\"[_]\\w+.diff\"), df)\n",
    "        #algoname = algoname.group(0)\n",
    "        \n",
    "        blamename = re.search((\"(?<=\\/csv\\/)(?:\\w.*)\"), blame)\n",
    "        blamename = blamename.group(0)\n",
    "        \n",
    "        with open (analyze_dir + r'04_annotate/02_diff-file_blame-file_comparison/patience_comparison/diff_' + fnames + \"_patience-\" + blamename, 'w') as csvfile:\n",
    "            writers = csv.writer(csvfile, delimiter = \",\")\n",
    "            header = ['bug_id', 'line_number', 'buggy_code', 'does_bugline_from_originfile?', 'date_added_in_originfile', 'earliest_affected_version', 'version_release_date', 'bug_class']\n",
    "            writers.writerow(header)\n",
    "            for item in blame_compare:\n",
    "                writers.writerow(item)\n",
    "                \n",
    "print ('\\nComparing buglines are complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
