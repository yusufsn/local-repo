{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, json, csv, subprocess, sys, re\n",
    "from urllib.request import urlopen\n",
    "from itertools import chain\n",
    "import urllib.request\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from git import *\n",
    "from subprocess import Popen, PIPE\n",
    "from os import path\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from plotly.offline import plot, init_notebook_mode, iplot\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userhome = os.path.expanduser('~')\n",
    "repository = userhome + r'/different-diff/dataset/openjpa/'\n",
    "analyze_dir = userhome + r'/different-diff/analyze/analyze_openjpa/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining git command function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_command(cmd, work_dir):\n",
    "    \"\"\"Executes a shell command in a subprocess, waiting until it has completed.\n",
    "    :param cmd: Command to execute.\n",
    "    :param work_dir: Working directory path.\n",
    "    \"\"\"\n",
    "    pipe = subprocess.Popen(cmd, shell=True, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    (out, error) = pipe.communicate()\n",
    "    return out, error\n",
    "    pipe.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding log messages containing bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applying git command to find commit log messages containing words of bugs, fix, defect or patch\n",
    "words = ['bug', 'fix', 'defect', 'patch']\n",
    "logs = []\n",
    "for n, word in enumerate(words):\n",
    "    git_cmd = \"git log --all --grep='\" + word + \"' --oneline\"\n",
    "    log = (str(execute_command(git_cmd, repository)).replace(\"b'\",'').replace('b\"','').replace('(','',1).replace(\"\\\\'\",\"'\").split(\"\\\\n\"))[:-1]\n",
    "\n",
    "    logs.append(log)\n",
    "\n",
    "com_logs = [item for sublist in logs for item in sublist]\n",
    "com_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#separating the commit id and the log messages\n",
    "commit = []\n",
    "for xx in range(0,len(com_logs)):\n",
    "    tmp = []\n",
    "    comm = com_logs[xx].split()\n",
    "    word = ' '.join(comm[1:])\n",
    "    tmp.extend([comm[0],word])\n",
    "    commit.append(tmp)\n",
    "\n",
    "for item in commit:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing bug ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Capturing bug ids which are identified as bug links in the log messages\n",
    "commitbugs = []\n",
    "buglinks = []\n",
    "\n",
    "for xx in range(0,len(com_logs)):\n",
    "    tmp = []\n",
    "    comm = com_logs[xx].split()\n",
    "    splitres = (str(comm[1:]))\n",
    "    letter = re.findall(r\"OPENJPA+[-][0-9]+\", splitres)\n",
    "    if letter != []:\n",
    "        commitbugs.extend(letter)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "commitbugs = set(commitbugs)\n",
    "for p,q in enumerate(commitbugs):\n",
    "    buglinks.append(q)\n",
    "buglinks = sorted(buglinks, reverse=True)\n",
    "print (buglinks)\n",
    "print (\"\\nNumber of bug id: \" + str(len(buglinks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Synchronizing the bug link with the bug report from JIRA ITS database\n",
    "errorlinks = []\n",
    "id_type = []\n",
    "for a,b in enumerate(buglinks):\n",
    "    link = \"https://issues.apache.org/jira/browse/\" + b\n",
    "    sys.stdout.write(\"\\r%i \" %(a+1) + \"Extracting: \" + b)\n",
    "    sys.stdout.flush()\n",
    "    try:\n",
    "        page = urllib.request.urlopen(link)\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        types = soup.find('span', attrs={'id':'type-val'}).text.replace(\"\\n\",'').replace(\" \",'').split(\",\")\n",
    "        types = sorted(types)\n",
    "        types.insert(0, b)\n",
    "        id_type.append(types)\n",
    "    except:\n",
    "        errorlinks.append(b)\n",
    "\n",
    "print(\"\\nExtraction has been completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding out if there were any error from the sync process above\n",
    "type_of_id = id_type\n",
    "errorlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Resync for the error bug ids identified\n",
    "error_links = []\n",
    "for a,b in enumerate(errorlinks):\n",
    "    link = \"https://issues.apache.org/jira/browse/\" + b\n",
    "    sys.stdout.write(\"\\r%i \" %(a+1) + \"Extracting: \" + b)\n",
    "    sys.stdout.flush()\n",
    "    try:\n",
    "        page = urllib.request.urlopen(link)\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        types = soup.find('span', attrs={'id':'type-val'}).text.replace(\"\\n\",'').replace(\" \",'').split(\",\")\n",
    "        types = sorted(types)\n",
    "        types.insert(0, b)\n",
    "        type_of_id.append(types)\n",
    "    except:\n",
    "        error_links.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type_of_id.sort()\n",
    "error_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bug_links = []\n",
    "for d, types in enumerate (type_of_id):\n",
    "    if types[1] == 'Bug':\n",
    "        bug_links.append(types[0])\n",
    "\n",
    "print (\"Number of bug id: \" + str(len(bug_links)))\n",
    "print (bug_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open (analyze_dir + \"01_code_document/txt_files/candidate_bug_links.txt\", mode=\"wt\", encoding=\"utf-8\") as myfile:\n",
    "    myfile.write('\\n'.join(bug_links))\n",
    "print (\"File candidate_bug_links.txt has been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting logs related to bug links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "com_log = []\n",
    "for no, bug_link in enumerate(bug_links):\n",
    "    sys.stdout.write(\"\\r%i \" %(no+1) + \"Extracting bug id: \" + bug_link)\n",
    "    sys.stdout.flush()\n",
    "    git_cmd = \"git log --all --oneline | grep -w '\" + bug_link + \"'\"\n",
    "    temp = (str(execute_command(git_cmd, repository)).replace(\"b'\",'').replace('b\"','').replace('(','',1)\n",
    "            .replace(\"\\\\\\\\n\",\"\\n\").split(\"\\\\n\"))[:-1]\n",
    "\n",
    "    com_log.append(temp)\n",
    "\n",
    "print (\"\\n\")\n",
    "for item in com_log:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturing bug id, and commit id related to the bug id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commits = []\n",
    "for x in range(0,len(com_log)):\n",
    "    com = []\n",
    "    com.append(bug_links[x])\n",
    "    for z in range(0,len(com_log[x])):\n",
    "        temp = str(com_log[x][z].split()[0:1]).replace(\"['\",'').replace(\"']\",'')\n",
    "        com.append(temp)\n",
    "    commits.append(com)\n",
    "print (commits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing bug-introducing change commit id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bugintro_cid = []\n",
    "for jj, kk in enumerate(commits):\n",
    "    if (len(kk) > 1):\n",
    "        bi_cid = kk[len(kk)-1:]\n",
    "        bi_cid.insert(0,kk[0])\n",
    "        bugintro_cid.append(bi_cid)\n",
    "print (len(bugintro_cid), \"\\n\")\n",
    "print (bugintro_cid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing candidate bug fix commit id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bugfix_cid = []\n",
    "for jj, kk in enumerate(commits):\n",
    "    if (len(kk) > 2):\n",
    "        bugfix_cid.append(kk[0:len(kk)-1])\n",
    "print (bugfix_cid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of candidate bug fix commit id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summ = 0\n",
    "for b, bfc in enumerate(bugfix_cid):\n",
    "    summ = summ + (len(bfc)-1)\n",
    "print (\"The number of candidate bug fix commit id = %i\" %summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bugintro = go.Bar(\n",
    "    x = ['Bug-introducing change commits'],\n",
    "    y = [len(bugintro_cid)],\n",
    "    name = 'Bug-introducing change commits',\n",
    "    text = [len(bugintro_cid)],\n",
    "    textposition = 'auto'\n",
    ")\n",
    "\n",
    "bugfix = go.Bar(\n",
    "    x = ['Candidate bug-fix commits'],\n",
    "    y = [summ],\n",
    "    name = 'Candidate bug-fix commits',\n",
    "    text = [summ],\n",
    "    textposition = 'auto'\n",
    ")\n",
    "\n",
    "data = [bugintro, bugfix]\n",
    "layout = go.Layout(\n",
    "    title = 'The number of commits in OPENJPA Project'\n",
    ")\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting parent_id of bug-intro commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_id = []\n",
    "for v, w in enumerate(bugintro_cid):\n",
    "    sys.stdout.write(\"\\rExtracting parent id from bug-intro commit: {} / {}\".format((v+1), len(bugintro_cid)))\n",
    "    sys.stdout.flush()\n",
    "    if w != []:\n",
    "        git_cmd = \"git log --pretty=%P -n1 \" + w[1]\n",
    "        temp = (str(execute_command(git_cmd, repository)).replace(\"b'\",'').replace('(','',1).split(\"\\\\n\"))[:-1]\n",
    "        if ' ' in temp[0]:\n",
    "            pr = temp[0].split(' ')\n",
    "            pr = pr[len(pr)-1:]\n",
    "            temps = [w,pr]\n",
    "        else:\n",
    "            temps = [w,temp]\n",
    "        newlist = list(chain.from_iterable(temps))\n",
    "\n",
    "    parent_id.append(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving parent id in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(analyze_dir + \"02_extracting_commitid/parentid_of_bugintro.csv\", 'w') as parent:\n",
    "    header = ['bug_id','bugintro_commitID','parent_id']\n",
    "    writers = csv.writer(parent, delimiter=',')\n",
    "    writers.writerow(header)\n",
    "    for item in parent_id:\n",
    "        writers.writerow(item)\n",
    "\n",
    "dfparent = pd.read_csv(analyze_dir + \"02_extracting_commitid/parentid_of_bugintro.csv\")\n",
    "dfparent = dfparent[header]\n",
    "dfparent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting commit_id of candidate bug fix commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bugfix_cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commit_idfix = []\n",
    "for y in range(0,len(bugfix_cid)):\n",
    "    sys.stdout.write(\"\\rExtracting commit id from candidate bug-fix commit: {} / {}\".format((y+1), len(bugfix_cid)))\n",
    "    sys.stdout.flush()\n",
    "    if w != []:\n",
    "        for s in range(1,len(bugfix_cid[y])):\n",
    "            temps = [bugfix_cid[y][0],bugfix_cid[y][s]]         \n",
    "            commit_idfix.append(temps)\n",
    "commit_idfix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(analyze_dir + \"02_extracting_commitid/commitid_of_candidatebugfix.csv\", 'w') as parentfix:\n",
    "    cols = ['bug_id','candidate_bugfix_commitID']\n",
    "    writers = csv.writer(parentfix, delimiter=',')\n",
    "    writers.writerow(cols)\n",
    "    for item in commit_idfix:\n",
    "        writers.writerow(item)\n",
    "\n",
    "dfcommitfix = pd.read_csv(analyze_dir + \"02_extracting_commitid/commitid_of_candidatebugfix.csv\")\n",
    "dfcommitfix = dfcommitfix[cols]\n",
    "dfcommitfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
